{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "be740435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dropout, Dense, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e252ef63",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikhi\\anaconda3\\envs\\Nikhils_Universe\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:312: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "C:\\Users\\nikhi\\anaconda3\\envs\\Nikhils_Universe\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:312: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "df= pd.read_excel(r\"DATASET.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "549ab19b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'year', 'Para-1', 'Para-2', 'Para-3', 'Para-4', 'Para-5',\n",
       "       'Para-6', 'Para-7', 'Para-8', 'Para-9', 'Para-10', 'Para-11', 'Para-12',\n",
       "       'Para-13'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f0325e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dd45211",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>Para-1</th>\n",
       "      <th>Para-2</th>\n",
       "      <th>Para-3</th>\n",
       "      <th>Para-4</th>\n",
       "      <th>Para-5</th>\n",
       "      <th>Para-6</th>\n",
       "      <th>Para-7</th>\n",
       "      <th>Para-8</th>\n",
       "      <th>Para-9</th>\n",
       "      <th>Para-10</th>\n",
       "      <th>Para-11</th>\n",
       "      <th>Para-12</th>\n",
       "      <th>Para-13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>324.0</td>\n",
       "      <td>354.5</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>117</td>\n",
       "      <td>2600</td>\n",
       "      <td>400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324.0</td>\n",
       "      <td>161.1</td>\n",
       "      <td>18.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>106</td>\n",
       "      <td>5950</td>\n",
       "      <td>1190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>324.0</td>\n",
       "      <td>170.7</td>\n",
       "      <td>18.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>5950</td>\n",
       "      <td>1190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>324.0</td>\n",
       "      <td>223.9</td>\n",
       "      <td>18.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>6150</td>\n",
       "      <td>1340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>324.0</td>\n",
       "      <td>228.2</td>\n",
       "      <td>18.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>113</td>\n",
       "      <td>6340</td>\n",
       "      <td>1450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>324.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>114</td>\n",
       "      <td>6630</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>324.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>103</td>\n",
       "      <td>6700</td>\n",
       "      <td>1540</td>\n",
       "      <td>0.9</td>\n",
       "      <td>25.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>324.0</td>\n",
       "      <td>100.6</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>114</td>\n",
       "      <td>6740</td>\n",
       "      <td>1590</td>\n",
       "      <td>0.9</td>\n",
       "      <td>52.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>324.0</td>\n",
       "      <td>176.5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>108</td>\n",
       "      <td>7175</td>\n",
       "      <td>1787</td>\n",
       "      <td>3.4</td>\n",
       "      <td>60.5</td>\n",
       "      <td>57.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>324.0</td>\n",
       "      <td>53.6</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>105</td>\n",
       "      <td>7567</td>\n",
       "      <td>1885</td>\n",
       "      <td>16.8</td>\n",
       "      <td>105.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1.960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>327.7</td>\n",
       "      <td>336.6</td>\n",
       "      <td>21.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>106</td>\n",
       "      <td>5810</td>\n",
       "      <td>2030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>327.7</td>\n",
       "      <td>240.2</td>\n",
       "      <td>22.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>104</td>\n",
       "      <td>5900</td>\n",
       "      <td>2200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>327.7</td>\n",
       "      <td>155.3</td>\n",
       "      <td>22.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>104</td>\n",
       "      <td>6100</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>327.7</td>\n",
       "      <td>77.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>105</td>\n",
       "      <td>6140</td>\n",
       "      <td>2650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>327.7</td>\n",
       "      <td>146.3</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>6200</td>\n",
       "      <td>2800</td>\n",
       "      <td>2.9</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6</td>\n",
       "      <td>327.7</td>\n",
       "      <td>216.3</td>\n",
       "      <td>21.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>111</td>\n",
       "      <td>6500</td>\n",
       "      <td>2550</td>\n",
       "      <td>34.8</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7</td>\n",
       "      <td>327.7</td>\n",
       "      <td>77.1</td>\n",
       "      <td>22.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>106</td>\n",
       "      <td>19437</td>\n",
       "      <td>7674</td>\n",
       "      <td>50.6</td>\n",
       "      <td>24.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8</td>\n",
       "      <td>327.7</td>\n",
       "      <td>90.3</td>\n",
       "      <td>22.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>105</td>\n",
       "      <td>22755</td>\n",
       "      <td>8472</td>\n",
       "      <td>56.7</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9</td>\n",
       "      <td>327.7</td>\n",
       "      <td>238.5</td>\n",
       "      <td>22.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>103</td>\n",
       "      <td>26640</td>\n",
       "      <td>9353</td>\n",
       "      <td>60.9</td>\n",
       "      <td>30.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>327.7</td>\n",
       "      <td>62.0</td>\n",
       "      <td>22.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>30525</td>\n",
       "      <td>10234</td>\n",
       "      <td>76.5</td>\n",
       "      <td>44.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year  Para-1  Para-2  Para-3  Para-4  Para-5  Para-6  Para-7  Para-8  \\\n",
       "0      1   324.0   354.5    17.0     0.0       3     117    2600     400   \n",
       "1      2   324.0   161.1    18.2     0.0       4     106    5950    1190   \n",
       "2      3   324.0   170.7    18.5     0.0       4     110    5950    1190   \n",
       "3      4   324.0   223.9    18.9     0.0       3     110    6150    1340   \n",
       "4      5   324.0   228.2    18.4     0.0       2     113    6340    1450   \n",
       "5      6   324.0   225.0    17.2     0.0       4     114    6630    1500   \n",
       "6      7   324.0   130.0    18.4     0.0       3     103    6700    1540   \n",
       "7      8   324.0   100.6    19.0     0.0       2     114    6740    1590   \n",
       "8      9   324.0   176.5    19.0     0.0       3     108    7175    1787   \n",
       "9     10   324.0    53.6    19.0     0.0       2     105    7567    1885   \n",
       "10     1   327.7   336.6    21.3     0.0       4     106    5810    2030   \n",
       "11     2   327.7   240.2    22.1     0.0       3     104    5900    2200   \n",
       "12     3   327.7   155.3    22.4     0.0       3     104    6100    2500   \n",
       "13     4   327.7    77.0    23.0     0.0       2     105    6140    2650   \n",
       "14     5   327.7   146.3    22.5     0.0       2     108    6200    2800   \n",
       "15     6   327.7   216.3    21.2     0.0       4     111    6500    2550   \n",
       "16     7   327.7    77.1    22.4     0.0       4     106   19437    7674   \n",
       "17     8   327.7    90.3    22.8     0.0       2     105   22755    8472   \n",
       "18     9   327.7   238.5    22.8     0.0       2     103   26640    9353   \n",
       "19    10   327.7    62.0    22.7     0.0       2     102   30525   10234   \n",
       "\n",
       "    Para-9  Para-10  Para-11  Para-12  Para-13  \n",
       "0      0.0      0.0      0.0        0    1.520  \n",
       "1      0.0      3.4      0.0        0    1.620  \n",
       "2      0.0     21.3      0.0        4    1.680  \n",
       "3      0.0     21.3      0.0        5    1.780  \n",
       "4      0.0     23.9      0.0        7    1.800  \n",
       "5      0.0     24.9      0.0        7    1.810  \n",
       "6      0.9     25.2      0.0        7    1.860  \n",
       "7      0.9     52.8      0.0        8    1.890  \n",
       "8      3.4     60.5     57.0        8    1.920  \n",
       "9     16.8    105.0     65.0        9    1.960  \n",
       "10     0.0      0.0      0.0        0    0.712  \n",
       "11     0.0      0.0      0.0        0    0.720  \n",
       "12     0.0      0.0      0.0        0    0.752  \n",
       "13     0.0      9.0      0.0        0    0.758  \n",
       "14     2.9     11.0      0.0        6    0.762  \n",
       "15    34.8     18.6      0.0        7    0.770  \n",
       "16    50.6     24.9      0.0        7    0.781  \n",
       "17    56.7     27.0      1.0        8    0.789  \n",
       "18    60.9     30.2      1.0        8    0.794  \n",
       "19    76.5     44.3      5.0        9    0.795  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "161059ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups=[]\n",
    "for i in range(0,len(df),10):\n",
    "    groups.append(df[i:i+10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "964641b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>Para-1</th>\n",
       "      <th>Para-2</th>\n",
       "      <th>Para-3</th>\n",
       "      <th>Para-4</th>\n",
       "      <th>Para-5</th>\n",
       "      <th>Para-6</th>\n",
       "      <th>Para-7</th>\n",
       "      <th>Para-8</th>\n",
       "      <th>Para-9</th>\n",
       "      <th>Para-10</th>\n",
       "      <th>Para-11</th>\n",
       "      <th>Para-12</th>\n",
       "      <th>Para-13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>2</td>\n",
       "      <td>454.0</td>\n",
       "      <td>1366.8</td>\n",
       "      <td>12.7</td>\n",
       "      <td>152.0</td>\n",
       "      <td>19</td>\n",
       "      <td>116</td>\n",
       "      <td>2223</td>\n",
       "      <td>525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>3</td>\n",
       "      <td>454.0</td>\n",
       "      <td>1310.5</td>\n",
       "      <td>13.3</td>\n",
       "      <td>57.9</td>\n",
       "      <td>17</td>\n",
       "      <td>114</td>\n",
       "      <td>2634</td>\n",
       "      <td>595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>4</td>\n",
       "      <td>454.0</td>\n",
       "      <td>1128.7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>12</td>\n",
       "      <td>121</td>\n",
       "      <td>3842</td>\n",
       "      <td>730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1.634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>5</td>\n",
       "      <td>454.0</td>\n",
       "      <td>1126.6</td>\n",
       "      <td>14.4</td>\n",
       "      <td>28.8</td>\n",
       "      <td>16</td>\n",
       "      <td>116</td>\n",
       "      <td>3842</td>\n",
       "      <td>730</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1.654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>6</td>\n",
       "      <td>454.0</td>\n",
       "      <td>931.8</td>\n",
       "      <td>13.6</td>\n",
       "      <td>125.0</td>\n",
       "      <td>13</td>\n",
       "      <td>116</td>\n",
       "      <td>4150</td>\n",
       "      <td>830</td>\n",
       "      <td>15.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>7</td>\n",
       "      <td>454.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13</td>\n",
       "      <td>118</td>\n",
       "      <td>4150</td>\n",
       "      <td>830</td>\n",
       "      <td>24.6</td>\n",
       "      <td>7.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>8</td>\n",
       "      <td>454.0</td>\n",
       "      <td>1124.1</td>\n",
       "      <td>14.9</td>\n",
       "      <td>45.0</td>\n",
       "      <td>18</td>\n",
       "      <td>117</td>\n",
       "      <td>4200</td>\n",
       "      <td>840</td>\n",
       "      <td>119.0</td>\n",
       "      <td>15.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16</td>\n",
       "      <td>1.862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>9</td>\n",
       "      <td>454.0</td>\n",
       "      <td>1462.3</td>\n",
       "      <td>13.2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>27</td>\n",
       "      <td>117</td>\n",
       "      <td>4400</td>\n",
       "      <td>720</td>\n",
       "      <td>138.2</td>\n",
       "      <td>30.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1.883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>10</td>\n",
       "      <td>454.0</td>\n",
       "      <td>986.3</td>\n",
       "      <td>14.3</td>\n",
       "      <td>67.0</td>\n",
       "      <td>24</td>\n",
       "      <td>122</td>\n",
       "      <td>4415</td>\n",
       "      <td>721</td>\n",
       "      <td>293.0</td>\n",
       "      <td>39.8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1.889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year  Para-1  Para-2  Para-3  Para-4  Para-5  Para-6  Para-7  Para-8  \\\n",
       "1000     2   454.0  1366.8    12.7   152.0      19     116    2223     525   \n",
       "1001     3   454.0  1310.5    13.3    57.9      17     114    2634     595   \n",
       "1002     4   454.0  1128.7    15.0    28.0      12     121    3842     730   \n",
       "1003     5   454.0  1126.6    14.4    28.8      16     116    3842     730   \n",
       "1004     6   454.0   931.8    13.6   125.0      13     116    4150     830   \n",
       "1005     7   454.0   703.0    14.5    17.0      13     118    4150     830   \n",
       "1006     8   454.0  1124.1    14.9    45.0      18     117    4200     840   \n",
       "1007     9   454.0  1462.3    13.2    62.0      27     117    4400     720   \n",
       "1008    10   454.0   986.3    14.3    67.0      24     122    4415     721   \n",
       "\n",
       "      Para-9  Para-10  Para-11  Para-12  Para-13  \n",
       "1000     0.0      0.0      0.0        2    1.492  \n",
       "1001     0.0      0.0      0.0        4    1.597  \n",
       "1002     0.0      0.0      0.0       15    1.634  \n",
       "1003    19.0      0.0      0.0       15    1.654  \n",
       "1004    15.1      1.8      1.0       15    1.681  \n",
       "1005    24.6      7.9      2.0       15    1.838  \n",
       "1006   119.0     15.7      2.0       16    1.862  \n",
       "1007   138.2     30.5      6.0       18    1.883  \n",
       "1008   293.0     39.8      7.0       18    1.889  "
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "1bf10683",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x=[]\n",
    "data_y=[]\n",
    "length= len(groups[0])-1\n",
    "for i in range(len(groups)):\n",
    "    data_x.append(groups[i][:length][:])\n",
    "    data_y.append(groups[i][length:length+1][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "274a936c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(data_x)):\n",
    "    data_x[i]= data_x[i].to_numpy()\n",
    "    data_y[i]= data_y[i].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "633f8dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x= data_x[:len(data_x)-1]\n",
    "data_y= data_y[:len(data_y)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "3b41a5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25]\n"
     ]
    }
   ],
   "source": [
    "deletion_rows=[]\n",
    "for i in range(len(data_x)):\n",
    "    if np.isnan(np.min(data_x[i])):\n",
    "        deletion_rows.append(i)\n",
    "print(deletion_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "18a5a293",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in deletion_rows:\n",
    "    data_x.pop(i)\n",
    "    data_y.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "74a39195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 97\n"
     ]
    }
   ],
   "source": [
    "print(len(data_x), len(data_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "2c3e2b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model2():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(32, 2, activation=\"relu\", input_shape=(13, 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='Adam', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "ea94e16b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_x= np.asarray(data_x)\n",
    "data_y= np.asarray(data_y, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "6e9b87ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y= train_test_split(data_x, data_y, random_state=45, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "41975a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x= np.asarray(train_x).astype('float32')\n",
    "#train_x=np.expand_dims(train_x, 1)\n",
    "train_y= np.asarray(train_y).astype('float32')\n",
    "#train_y=np.expand_dims(train_y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "e8c010e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x= np.asarray(test_x).astype('float32')\n",
    "#test_x=np.expand_dims(test_x, 1)\n",
    "test_y= np.asarray(test_y).astype('float32')\n",
    "#test_y=np.expand_dims(test_y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "f3917f71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 599ms/step - loss: 4844447.0000 - acc: 0.1719 - val_loss: 7688242.0000 - val_acc: 0.2950\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4842544.0000 - acc: 0.2326 - val_loss: 7686142.0000 - val_acc: 0.3250\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 4841825.5000 - acc: 0.2917 - val_loss: 7683974.0000 - val_acc: 0.3700\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4839767.5000 - acc: 0.2882 - val_loss: 7681689.5000 - val_acc: 0.4200\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 4837206.0000 - acc: 0.3559 - val_loss: 7679216.5000 - val_acc: 0.4900\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 4834508.0000 - acc: 0.3854 - val_loss: 7676509.5000 - val_acc: 0.5400\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 4833444.5000 - acc: 0.4080 - val_loss: 7673557.0000 - val_acc: 0.5800\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4829123.5000 - acc: 0.3941 - val_loss: 7670329.5000 - val_acc: 0.6200\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4828438.5000 - acc: 0.4983 - val_loss: 7666799.5000 - val_acc: 0.6700\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4823697.0000 - acc: 0.5434 - val_loss: 7662932.5000 - val_acc: 0.6900\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 4822026.0000 - acc: 0.5382 - val_loss: 7658604.0000 - val_acc: 0.7200\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 4818483.5000 - acc: 0.5833 - val_loss: 7653870.5000 - val_acc: 0.7600\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 4817190.0000 - acc: 0.5729 - val_loss: 7648698.0000 - val_acc: 0.8000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4811223.0000 - acc: 0.5764 - val_loss: 7643104.5000 - val_acc: 0.8600\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 4806267.0000 - acc: 0.6198 - val_loss: 7637028.5000 - val_acc: 0.9000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4802059.5000 - acc: 0.6597 - val_loss: 7630452.0000 - val_acc: 0.9100\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4795168.0000 - acc: 0.6788 - val_loss: 7623360.5000 - val_acc: 0.9100\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4792825.5000 - acc: 0.7083 - val_loss: 7615700.0000 - val_acc: 0.9150\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4784770.0000 - acc: 0.7274 - val_loss: 7607415.0000 - val_acc: 0.9150\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4773727.5000 - acc: 0.7517 - val_loss: 7598383.5000 - val_acc: 0.9150\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4774582.0000 - acc: 0.7344 - val_loss: 7588618.0000 - val_acc: 0.9150\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4765834.0000 - acc: 0.7517 - val_loss: 7577858.5000 - val_acc: 0.9150\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4757870.0000 - acc: 0.7604 - val_loss: 7566171.5000 - val_acc: 0.9150\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 4748690.0000 - acc: 0.7708 - val_loss: 7553607.5000 - val_acc: 0.9150\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4741757.5000 - acc: 0.7882 - val_loss: 7540139.0000 - val_acc: 0.9200\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4727957.0000 - acc: 0.8021 - val_loss: 7525650.0000 - val_acc: 0.9200\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4720550.0000 - acc: 0.7934 - val_loss: 7510125.0000 - val_acc: 0.9200\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 4714666.5000 - acc: 0.7743 - val_loss: 7493451.5000 - val_acc: 0.9200\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 4700352.5000 - acc: 0.7882 - val_loss: 7475723.0000 - val_acc: 0.9200\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4685319.5000 - acc: 0.7882 - val_loss: 7456749.5000 - val_acc: 0.9200\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4663189.0000 - acc: 0.7743 - val_loss: 7436516.0000 - val_acc: 0.9200\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4649116.5000 - acc: 0.8125 - val_loss: 7414945.5000 - val_acc: 0.9200\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4635774.5000 - acc: 0.8073 - val_loss: 7391959.5000 - val_acc: 0.9200\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4608618.0000 - acc: 0.7865 - val_loss: 7367474.0000 - val_acc: 0.9200\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4594950.0000 - acc: 0.8056 - val_loss: 7341575.0000 - val_acc: 0.9200\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4578191.0000 - acc: 0.8038 - val_loss: 7314158.0000 - val_acc: 0.9200\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 4560736.5000 - acc: 0.7726 - val_loss: 7285088.0000 - val_acc: 0.9200\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 4542613.5000 - acc: 0.8090 - val_loss: 7254358.5000 - val_acc: 0.9200\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4514812.5000 - acc: 0.8212 - val_loss: 7221831.0000 - val_acc: 0.9200\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4475774.0000 - acc: 0.8125 - val_loss: 7187472.5000 - val_acc: 0.9200\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 4484724.5000 - acc: 0.8108 - val_loss: 7151369.5000 - val_acc: 0.9200\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4431577.5000 - acc: 0.8212 - val_loss: 7113275.0000 - val_acc: 0.9200\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4411391.5000 - acc: 0.8229 - val_loss: 7073198.0000 - val_acc: 0.9200\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 4402008.0000 - acc: 0.8108 - val_loss: 7031221.0000 - val_acc: 0.9200\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 4363302.5000 - acc: 0.8438 - val_loss: 6986961.5000 - val_acc: 0.9200\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4302727.0000 - acc: 0.8646 - val_loss: 6940246.0000 - val_acc: 0.9200\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 4284693.5000 - acc: 0.8438 - val_loss: 6890784.0000 - val_acc: 0.9200\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 4246736.0000 - acc: 0.8507 - val_loss: 6838458.0000 - val_acc: 0.9200\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 4209560.0000 - acc: 0.8507 - val_loss: 6783915.0000 - val_acc: 0.9200\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4162012.0000 - acc: 0.8628 - val_loss: 6726585.0000 - val_acc: 0.9200\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 4139214.7500 - acc: 0.8889 - val_loss: 6666900.5000 - val_acc: 0.9200\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 4103263.5000 - acc: 0.8854 - val_loss: 6604218.0000 - val_acc: 0.9200\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 4052014.7500 - acc: 0.9028 - val_loss: 6537982.5000 - val_acc: 0.9200\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3978167.0000 - acc: 0.9115 - val_loss: 6468057.0000 - val_acc: 0.9200\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3927621.7500 - acc: 0.9132 - val_loss: 6393204.5000 - val_acc: 0.9200\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3900287.0000 - acc: 0.9132 - val_loss: 6313213.0000 - val_acc: 0.9200\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3842540.5000 - acc: 0.9132 - val_loss: 6228354.5000 - val_acc: 0.9200\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 3753317.2500 - acc: 0.9132 - val_loss: 6139329.5000 - val_acc: 0.9200\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3726044.5000 - acc: 0.9149 - val_loss: 6044317.5000 - val_acc: 0.9200\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3635957.7500 - acc: 0.9167 - val_loss: 5944391.0000 - val_acc: 0.9200\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3631700.5000 - acc: 0.9167 - val_loss: 5840627.0000 - val_acc: 0.9200\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3530689.0000 - acc: 0.9167 - val_loss: 5732096.5000 - val_acc: 0.9200\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3406561.0000 - acc: 0.9167 - val_loss: 5619417.5000 - val_acc: 0.9200\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3361341.0000 - acc: 0.9167 - val_loss: 5503262.5000 - val_acc: 0.9200\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3321109.5000 - acc: 0.9167 - val_loss: 5382446.5000 - val_acc: 0.9200\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3222155.2500 - acc: 0.9167 - val_loss: 5259593.5000 - val_acc: 0.9200\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3162134.5000 - acc: 0.9167 - val_loss: 5133141.0000 - val_acc: 0.9200\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3051627.0000 - acc: 0.9167 - val_loss: 5003695.5000 - val_acc: 0.9200\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2956459.5000 - acc: 0.9167 - val_loss: 4871986.0000 - val_acc: 0.9200\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2950362.2500 - acc: 0.9167 - val_loss: 4738561.5000 - val_acc: 0.9200\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2830240.5000 - acc: 0.9167 - val_loss: 4603158.5000 - val_acc: 0.9200\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2791974.5000 - acc: 0.9167 - val_loss: 4466806.5000 - val_acc: 0.9200\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2584649.7500 - acc: 0.9167 - val_loss: 4328927.5000 - val_acc: 0.9200\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2532487.2500 - acc: 0.9167 - val_loss: 4191838.0000 - val_acc: 0.9200\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2427535.0000 - acc: 0.9167 - val_loss: 4053740.2500 - val_acc: 0.9200\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2414737.7500 - acc: 0.9167 - val_loss: 3915492.2500 - val_acc: 0.9200\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2320175.0000 - acc: 0.9167 - val_loss: 3778356.5000 - val_acc: 0.9200\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2253188.5000 - acc: 0.9167 - val_loss: 3641875.5000 - val_acc: 0.9200\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2158664.0000 - acc: 0.9167 - val_loss: 3507345.2500 - val_acc: 0.9200\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2082919.3750 - acc: 0.9167 - val_loss: 3375443.2500 - val_acc: 0.9200\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1967720.5000 - acc: 0.9167 - val_loss: 3246472.2500 - val_acc: 0.9200\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2006670.0000 - acc: 0.9167 - val_loss: 3121511.7500 - val_acc: 0.9200\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1706739.7500 - acc: 0.9167 - val_loss: 3000283.2500 - val_acc: 0.9200\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1737948.2500 - acc: 0.9167 - val_loss: 2886029.7500 - val_acc: 0.9200\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1733791.7500 - acc: 0.9167 - val_loss: 2778027.5000 - val_acc: 0.9200\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1748283.3750 - acc: 0.9167 - val_loss: 2678909.5000 - val_acc: 0.9200\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1542386.3750 - acc: 0.9167 - val_loss: 2589002.2500 - val_acc: 0.9200\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1534586.0000 - acc: 0.9167 - val_loss: 2507488.7500 - val_acc: 0.9200\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1518862.5000 - acc: 0.9167 - val_loss: 2435223.0000 - val_acc: 0.9200\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1399651.0000 - acc: 0.9167 - val_loss: 2372865.2500 - val_acc: 0.9200\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1353819.0000 - acc: 0.9167 - val_loss: 2321373.2500 - val_acc: 0.9200\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1349022.1250 - acc: 0.9167 - val_loss: 2279407.2500 - val_acc: 0.9200\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1515106.3750 - acc: 0.9167 - val_loss: 2247308.0000 - val_acc: 0.9200\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1360338.0000 - acc: 0.9167 - val_loss: 2224940.7500 - val_acc: 0.9200\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1308547.5000 - acc: 0.9167 - val_loss: 2210867.2500 - val_acc: 0.9200\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1351055.1250 - acc: 0.9167 - val_loss: 2203353.7500 - val_acc: 0.9200\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1531191.7500 - acc: 0.9167 - val_loss: 2202530.5000 - val_acc: 0.9200\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1375285.8750 - acc: 0.9167 - val_loss: 2205529.2500 - val_acc: 0.9200\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1273027.2500 - acc: 0.9167 - val_loss: 2211717.5000 - val_acc: 0.9200\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1507020.0000 - acc: 0.9167 - val_loss: 2219647.2500 - val_acc: 0.9200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f9f9681670>"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= get_model2()\n",
    "model.fit(train_x, train_y, epochs=100, batch_size=128, validation_data=(test_x, test_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
